[{"title":"GPU并行","url":"/2023/11/20/GPU%E5%B9%B6%E8%A1%8C/","content":" 简介\n主要针对transformer大模型架构，megatron-LM框架。\n资料\nNVIDIA/Megatron-LM   官网里面给出了经典的3篇文章\n常见的分布式并行策略 - OneFlow\n并行技术 | Colossal-AI (colossalai.org)\n 数据并行\nDP，要 all-reduce 互相传梯度。\n zero1\n对于 optimizer states 的切分。每个gpu只维护一部分优化器状态，也只更新一部分参数。这样显存和计算都减少了。\n\n通信量并没有增加。Ring AllReduce就是分为两个步骤：reduce-scatter和 all-gather。\n通信量：$2\\times (N-1)  \\times  \\frac{K}{N} $    k是数据大小，N个GPU\n资料\nRing AllReduce简介 \n 张量并行\n将attention、MLP拆开。只要在g处做all-reduce加在一起就行。\n\n sequence parallel\n将 layernorm 和 dropout 按sequence维度也拆分。通信g是前向的all-gather，反向reduce-scatter，g^\\hat{g}g^​相反。同样通信量也没有增加。\n\n 流水线并行\nGpipe。算完前向再算反向。\n\n1F1B、交错流水线 。上面是1F1B，保持进行中的微批次数量里只有4个（与管道深度一样），这样相比Gpipe显存会更小。\nlayers 16，pp4配置下。1F1B划分：1-4，5-8，9-12，13-16。交错流水线可以1-2，9-10；3-4，11-12；5-6，13-14；7-8，15-16这样划分，可以理解为先把模型划分成几块（2块），再依次划分给GPU。这样需要更多轮1234才能算完（2次）一个前（反）向，但是时间也相应减小了，使得bubble占比更小。\n\n moe专家并行\n基于 Transformer 的 MoE，即将 Transformer 中的 MLP 层替换为 MoE 层。其他操作没变。\n从数据并行到专家并行需要转化切分维度，做all-to-all操作。\n在megatron中，是用all-gather、reduce-scatter实现all-to-all功能的。\n\n","tags":["GPU并行"]},{"title":"linux使用","url":"/2022/12/12/Linux%E4%BD%BF%E7%94%A8/","content":"linux的基本使用。自己电脑用wsl就可以，谷歌的colab在线环境也挺好。\n 常用命令\n查找文件。/: 表示从根目录开始查找。\nfind / -name &quot;local&quot;\n 常用配置\n更换pip清华源，快的飞起。\npip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n docker\npython ，pytorch，cuda都要相互兼容。可以用官方提供的docker。\ncuda版本用这个看 ，其他的如nvidia-smi都不是。  pytorch类似。\npython -c &quot;import torch; print(torch.version.cuda)&quot;\ndocker run的时候要-v挂载数据， --shm-size扩大空间。docker工作目录命名为workspace，还得重新命名。\ndocker run -it --name ydshi_3_1 --gpus all --shm-size=1G -v /home/ydshi/data:/workspace nvcr.io/nvidia/pytorch:22.04-py3 /bin/bash\n创建完容器之后重新打开\ndocker start ydshi_3_1docker exec -it ydshi_3_1 /bin/bash \n查看镜像\ndocker images\n查看容器\ndocker ps \n ssh\n连接需要用户名、ip地址、密码。默认端口22。\nssh username@host\n可以在vscode里面下载插件，打开服务器的文件夹\n WSL2\nwindows开启Linux子系统设置\nms store里面下个20.04ubuntu\n再在vscode中打开，原生环境编程就很方便，不用在windows里折腾。\n VM虚拟机\nubuntu NAT联网，自己的连接的网络得设置共享，直接搜控制面板就好。在VM中设置虚拟网络编辑器，还原默认值，还要用管理员打开。\n调整屏幕分辨率，设成自由拉伸\n安装 tweak 优化\n设置open-vm-tools，不是用vm-tools！\n","tags":["linux"]},{"title":"Megatron-LM实验","url":"/2023/10/19/Megatron-LM%E5%AE%9E%E9%AA%8C/","content":" 运行megatron\n运行环境如下，还需要注释trans engine模块，参数   --transformer-impl local\ndocker run -it --name ydshi_3_1 --gpus all --shm-size=1G -v /home/ydshi/data:/workspace nvcr.io/nvidia/pytorch:22.04-py3 /bin/bash\ngpt需要下载vocab，merges 2个文件，可以在hugging face下载到。按官网教程预处理数据。将sh脚本补充完整，并自定义好参数，GPUS_PER_NODE、tp、pp等。\n\n运行命令就可以了。\nbash examples/pretrain_gpt_distributed_with_mp.sh &gt; record.txt \n tips\n no.1\n在主机bash下删除不了文件，这时候可以将文件挂载到docker容器中删除。\n no.2\nCUDA out of memory，就是显存不够了，可以减小一些参数。\n​    --num-layers 12 \n​    --hidden-size 256 \\\n 统计nccl通信占比\n在interation 代码前后插入 torch.cuda.nvtx.range_push   、 …pop tag。运行时前面加上nsys profile，在windows 使用NsightSystems 进行可视化查看。（一般第一个iteration是warm up，可以设置成5、10）\n\n下载师兄改版的pyprof，使用myrun.sh 将nsys文件转化成 csv表格。在可视化文件中复制iteration的信息（要找default stream），如图。\nName\tStart\tDuration\tTID\tGPU\tContextDescription of the event [968.163 ms]\t18.0755s\t968.163 ms\t117199\tGPU 1\tStream 7\n将信息复制到interation.py,正则表达式提取信息，并调用algo.py 得到时间占比。\nalgo.py 是统计kernel时间的，在megatron-LM/result文件夹。\n myrun.sh\nnsys profile bash examples/pretrain_gpt_distributed_with_mp.sh &gt; record.txt nsys stats --report=sqlite  pp4.nsys-reppython3 -m pyprof.parse pp4.sqlite &gt; pp4.jsonpython3 -m pyprof.prof --csv -c idx,kernel,sil,device,stream,start,end,grid,block pp4.json &gt; pp4.csv\n","tags":["Megatron-LM"]},{"title":"transformer","url":"/2023/11/01/transformer/","content":"\n embedding\n参数维度大小是（v,h），v是词表总量，h是hidden_size。 每个词有个整数索引，embedding后就是对应索引的那行，python代码中张量直接套一个索引就得出了。\n self-attention\n能提取序列的关系，取代了之前的RNN，方便并行。\n由input a1分别算出q，k，v。attention就是每个词之间的关系，q1乘其他词的k得到，最后拿attention乘对应的v 再加起来，就是output b1。要训练的就是Wq,Wk,Wv。\n\nmuti-head就是多个self-attention，可以提取不同角度的信息。\n资料\nTransformer - YouTube   李宏毅老师讲的超级好\n","tags":["transformer"]},{"title":"深度学习基础","url":"/2023/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/","content":" 常用方法\n Cross Entropy Loss\n交叉熵主要用于度量两个概率分布间的差异性。标签值 y（分类时用one-hot编码，真实类别是1，其他为0）， 预测值 a，分类数n\n loss =−∑j=1nyjln⁡aj\\text { loss }=-\\sum_{j=1}^n y_j \\ln a_j\n loss =−j=1∑n​yj​lnaj​\n softmax\n多类别分类的激活函数，将一组实数转化为表示概率分布的值。每个元素都在 0 到 1 之间，且所有元素的和为 1。\n给定输入向量 z=(z1,z2,…,zk)z=\\left(z_1, z_2, \\ldots, z_k\\right)z=(z1​,z2​,…,zk​) ，计算公式为:\nσ(z)i=ezi∑j=1kezj，i=1,2,…,k\\begin{aligned}\n\\sigma(z)_i=\\frac{e^{z_i}}{\\sum_{j=1}^k e^{z_j}}，i=1,2, \\ldots, k\n\\end{aligned}\nσ(z)i​=∑j=1k​ezj​ezi​​，i=1,2,…,k​\n其中， eee 是自然对数的底， kkk 是类别的数量。\n larynorm\n\n用于加速训练的。对单个样本的不同特征做归一化操作，公式：\nμi=1n∑j=1nxijσi2=1m∑j=1m(xij−μi)2x^ij=xij−μiσi2+ϵ\\begin{aligned}\n\\mu_i &amp; =\\frac{1}{n} \\sum_{j=1}^n x_{i j} \\\\\n\\sigma_i^2 &amp; =\\frac{1}{m} \\sum_{j=1}^m\\left(x_{i j}-\\mu_i\\right)^2 \\\\\n\\hat{x}_{i j} &amp; =\\frac{x_{i j}-\\mu_i}{\\sqrt{\\sigma_i^2+\\epsilon}}\n\\end{aligned}\nμi​σi2​x^ij​​=n1​j=1∑n​xij​=m1​j=1∑m​(xij​−μi​)2=σi2​+ϵ​xij​−μi​​​\n\\begin{aligned}\n \n\n \\end{aligned}\n\n dropout\n用于防止神经网络过拟合。在训练过程中，随机地将一部分神经元的输出设置为零。\n资料\n[03.2 交叉熵损失函数 - AI-EDU (microsoft.github.io)](https://microsoft.github.io/ai-edu/基础教程/A2-神经网络基本原理/第1步 - 基本知识/03.2-交叉熵损失函数/)\n 优化器\n深度学习的优化目标是最小化目标（损失）函数，就是反向传播算梯度从而更新参数。不同优化器区别在于q函数。\n待优化参数: θ\\thetaθ ，目标函数： f(θ)f(\\theta)f(θ) ，学习率: α\\alphaα\nt\\mathrm{t}t 时刻参数的梯度: gt=∇f(θt)g_t=\\nabla f\\left(\\theta_t\\right)gt​=∇f(θt​)\n优化通式：  θt=θt−1−q(gt)\\theta_t=\\theta_{t-1}-q\\left(g_t\\right)θt​=θt−1​−q(gt​)\n SGD\nSGD的梯度下降过程，类似于一个小球从山坡上滚下，它的前进方向只与当前山坡的最大倾斜方向一致(梯度反方向)，每一个时刻的初速度都为０。\nθt=θt−1−α∗gt\\begin{aligned}\n\n\\theta_t=\\theta_{t-1}-\\alpha * g_t\n\n \\end{aligned}\nθt​=θt−1​−α∗gt​​\nSGD容易收敛到局部最优，在某些情况下可能被困在鞍点。\n引入 Momentum\nmt= momentum ∗mt−1+α∗gtθt=θt−1−mt\\begin{aligned}\n\nm_t &amp; =\\text { momentum } * m_{t-1}+\\alpha * g_t \\\\\n\\theta_t &amp; =\\theta_{t-1}-m_t\n\n\\end{aligned}\nmt​θt​​= momentum ∗mt−1​+α∗gt​=θt−1​−mt​​\n假设momentum =0.9,$ \\alpha=0.01$, 有:\nm5=0.9m4+0.01g5m4=0.9m3+0.01g4m3=0.9m2+0.01g3m2=0.9m1+0.01g2\\begin{aligned}\n&amp; m_5=0.9 m_4+0.01 g_5 \\\\\n&amp; m_4=0.9 m_3+0.01 g_4 \\\\\n&amp; m_3=0.9 m_2+0.01 g_3 \\\\\n&amp; m_2=0.9 m_1+0.01 g_2\n\\end{aligned}\n​m5​=0.9m4​+0.01g5​m4​=0.9m3​+0.01g4​m3​=0.9m2​+0.01g3​m2​=0.9m1​+0.01g2​​\n则: m5=0.01∗(g5+0.9g5+0.92g3+0.93g2+0.94g1)m_5=0.01 *\\left(g_5+0.9 g_5+0.9^2 g_3+0.9^3 g_2+0.9^4 g_1\\right)m5​=0.01∗(g5​+0.9g5​+0.92g3​+0.93g2​+0.94g1​)\n可以看到第5次更新的梯度包含了前4次的梯度，且是一个指数衰减的过程。\nSGD Momentum的梯度下降过程，前进方向由当前山坡的最大倾斜方向与之前的下降方向共同决定，小球具有初速度(动量)。\n Adam\nmt=β1mt−1+(1−β1)gtm^t=mt1−β1tVt=β2Vt−1+(1−β2)gt2V^t=Vt1−β2tαt=αV^t+ϵθt=θt−1−αt∗m^t\\begin{aligned}\nm_t &amp; =\\beta_1 m_{t-1}+\\left(1-\\beta_1\\right) g_t \\\\\n\\hat{m}_t &amp; =\\frac{m_t}{1-\\beta_1^t} \\\\\nV_t &amp; =\\beta_2 V_{t-1}+\\left(1-\\beta_2\\right) g_t^2 \\\\\n\\hat{V}_t &amp; =\\frac{V_t}{1-\\beta_2^t} \\\\\n\\alpha_t &amp; =\\frac{\\alpha}{\\sqrt{\\hat{V}_t}+\\epsilon} \\\\\n\\theta_t &amp; =\\theta_{t-1}-\\alpha_t * \\hat{m}_t    \\\\\n\n\\end{aligned}\nmt​m^t​Vt​V^t​αt​θt​​=β1​mt−1​+(1−β1​)gt​=1−β1t​mt​​=β2​Vt−1​+(1−β2​)gt2​=1−β2t​Vt​​=V^t​​+ϵα​=θt−1​−αt​∗m^t​​\n二阶动量$V_t $ 是历史梯度平方和，度量历史更新频率。参数更新越频繁，二阶动量越大，学习率就越小。m^t、V^t\\hat{m}_t 、\\hat{V}_tm^t​、V^t​是偏差修正。\n资料\nBack Propagation and Gradient Calculation in Deep Learning (hannlp.github.io)\n下篇 反向传播的微积分原理_哔哩哔哩_bilibili\noptimizer优化器总结 - weber’s Blog (haiping.vip)\n cnn\n有卷积层、池化层。反向计算梯度时看前向计算对后面的影响，从而有相应的系数。\n资料\n卷积神经网络(CNN)反向传播算法 - 刘建平Pinard - 博客园 (cnblogs.com)\n conv2d结构\nConv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n这个卷积层参数：64×3×9+64=179264\\times3\\times9+64 = 179264×3×9+64=1792\n一个通道的结果： 输入的3个通道各自经过一个卷积核再相加得到的，卷积核个数=输出通道*输入通道，每个通道还有有一个偏置。\n资料\n深度学习 | 卷积操作参数量和计算量 · zilch个人博客 (hezl1592.github.io)  图很形象\n","tags":["深度学习"]},{"title":"方法记录","url":"/2023/12/26/%E6%96%B9%E6%B3%95%E8%AE%B0%E5%BD%95/","content":" 查找新模型\nPyTorch库 timm有很多SOTA模型 huggingface/pytorch-image-models ，再结合 模型榜单 就能知道最新的模型了。\ntimm 库引用模型并打印结构\nmodel = timm.create_model(&#x27;coatnet_0_224&#x27;)for name, param in model.named_parameters():    print(f&quot;Parameter name: &#123;name&#125;, &#123;param.size()&#125;&quot;)\n","tags":["方法记录"]},{"title":"博客使用","url":"/2022/09/02/%E5%AE%8C%E7%BB%93/hexo%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8/","content":"hexo+keep主题的静态网站。\n我需要的博客功能：\nA：代码折叠，数学公式，简洁美观。\n文章不想公开时：\nA：用密码访问，在静态仓库能看到。可以放在_draft文件不上传，在本地先看着。\nGit Bash进入博客目录中（D:\\blog，D:\\blog\\source\\_posts都行）。\n常用命令：\nhexo clean  # 清除缓存hexo g      # 生成静态网页hexo s      #启动服务器，本地查看hexo d      # 部署到Github\n 图床\n使用PicGO在github上创建图床，picgo要打开时间戳重命名。\n还要下载compress插件，搭配压缩网站（tinify.com)  。\ntypora平时就复制图片到统一文件夹如typora/img,是博客的文档就手动将图片上传。本地要发给别人也简单，用python脚本将图片移到同一文件夹，改下引用格式就行。\n 数学公式\n如何在 hexo 中支持 Mathjax  这个实测简单好使\n tips1\n修改仓库,这样hexo d好使点\nrepository: git@github.com:shiyandong/shiyandong.github.io.git#repository: https://github.com/shiyandong/shiyandong.github.io.git\n tips2\n默认的git bash的框太丑了，也不能缩放。得把git bash加到windows终端里面。\n","tags":["blog"]},{"title":"DDP demo","url":"/2024/01/03/%E4%BB%A3%E7%A0%81demo/DDP%20demo/","content":"DDP demo\ntorch中DDP比DP效果好，用torchrun启动程序。\nimport torchimport torch.nn as nnimport torchvision.models as modelsfrom torch.nn.parallel import DistributedDataParallel as DDPimport torch.distributed as distnum_classes = 4  num_epochs = 10batch_size = 512def train():  dist.init_process_group(&quot;nccl&quot;)  rank = dist.get_rank()  print(f&quot;Start running basic DDP example on rank &#123;rank&#125;.&quot;)  vgg = models.vgg16(pretrained=True)  vgg = DDP(vgg.to(rank), device_ids=[rank])  loss = nn.CrossEntropyLoss()  optimizer = torch.optim.SGD(vgg.parameters(), lr=0.001, momentum=0.9)  for _ in range(num_epochs):    optimizer.zero_grad()    images = torch.randn(batch_size, 3, 64, 64)    labels = torch.randint(size=(batch_size,), low=0, high=num_classes).to(rank)    outputs = vgg(images)    loss(outputs, labels).backward()    optimizer.step()     dist.destroy_process_group()if __name__ == &#x27;__main__&#x27;:  train()&#x27;&#x27;&#x27;torchrun --nnodes=1 --nproc_per_node=4  --master_port 12480 vgg_mul4.py&#x27;&#x27;&#x27;\n","tags":["torch","数据并行"]},{"title":"修改conda默认安装路径","url":"/2022/11/23/%E5%AE%8C%E7%BB%93/%E4%BF%AE%E6%94%B9conda%E9%BB%98%E8%AE%A4%E5%AE%89%E8%A3%85%E8%B7%AF%E5%BE%84/","content":" 操作流程\n打开 C:\\Users(用户)\\username\\ .condarc 文件，如果没有，执行命令：\nconda config --set show_channel_urls yes\n查看conda配置信息，执行命令查看。第一个路径就是默认的路径。\nconda config --show\n通过命令修改，add后自动调整为第一个路径。用“/”\nconda config --add envs_dirs E:/File/Anaconda3/envs\n 若修改后并未生效\n需要修改 D:\\Anaconda3 的权限。右击属性，选择安全，选择Users，点击编辑，将 Users的权限全被设为允许（特殊权限可不设）。\n","tags":["conda"]}]