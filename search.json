[{"title":"GPU并行","url":"/2023/11/20/%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86/GPU%E5%B9%B6%E8%A1%8C/","content":"简介主要针对transformer大模型架构，megatron-LM框架。\n资料\nNVIDIA/Megatron-LM   官网里面给出了经典的3篇文章\n常见的分布式并行策略 - OneFlow\n并行技术 | Colossal-AI (colossalai.org)\n数据并行DP，要 all-reduce 互相传梯度。\nzero1 对于 optimizer states 的切分。每个gpu只维护一部分优化器状态，也只更新一部分参数。这样显存和计算都减少了。\n\n通信量并没有增加。Ring AllReduce就是分为两个步骤：reduce-scatter和 all-gather。\n通信量：$2\\times (N-1)  \\times  \\frac{K}{N} $    k是数据大小，N个GPU\n资料\nRing AllReduce简介 \n张量并行将attention、MLP拆开。只要在g处做all-reduce加在一起就行。\n\nsequence parallel将 layernorm 和 dropout 按sequence维度也拆分。通信g是前向的all-gather，反向reduce-scatter，$\\hat{g}$相反。同样通信量也没有增加。\n\n流水线并行Gpipe。算完前向再算反向。\n\n1F1B、交错流水线 。上面是1F1B，保持进行中的微批次数量里只有4个（与管道深度一样），这样相比Gpipe显存会更小。\nlayers 16，pp4配置下。1F1B划分：1-4，5-8，9-12，13-16。交错流水线可以1-2，9-10；3-4，11-12；5-6，13-14；7-8，15-16这样划分，可以理解为先把模型划分成几块（2块），再依次划分给GPU。这样需要更多轮1234才能算完（2次）一个前（反）向，但是时间也相应减小了，使得bubble占比更小。\n\nmoe专家并行基于 Transformer 的 MoE，即将 Transformer 中的 MLP 层替换为 MoE 层。其他操作没变。\n从数据并行到专家并行需要转化切分维度，做all-to-all操作。\n在megatron中，是用all-gather、reduce-scatter实现all-to-all功能的。\n\n","tags":["GPU并行"]},{"title":"Transformer","url":"/2023/11/01/%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86/transformer/","content":"embedding参数维度大小是（v,h），v是词表总量，h是hidden_size。 每个词有个整数索引，embedding后就是对应索引的那行，python代码中张量直接套一个索引就得出了。\nself-attention能提取序列的关系，取代了之前的RNN，方便并行。\n由input a1分别算出q，k，v。attention就是每个词之间的关系，q1乘其他词的k得到，最后拿attention乘对应的v 再加起来，就是output b1。要训练的就是Wq,Wk,Wv。\n\nmuti-head就是多个self-attention，可以提取不同角度的信息。\n资料\nTransformer - YouTube   讲的很清楚\n","tags":["transformer"]},{"title":"并行训练","url":"/2024/01/03/%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86/%E5%B9%B6%E8%A1%8C%E8%AE%AD%E7%BB%83/","content":"数据并行pytorch中DDP比DP效果好，\n可以用torchrun启动，也能用多线程普通启动\n待了解\n\n[ ] hugging face 的accelerate\n\n","tags":["并行"]},{"title":"推理","url":"/2024/04/05/%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86/%E6%8E%A8%E7%90%86/","content":"LLM类加载模型时首先根据参数生成llm_engine类\n\nprefiil - decode 2个阶段\nKV-cache 缓存，token -&gt; token 生成下一个token需要当前的Q，和之前所有的KV。\n资料\nLLM推理入门指南②：深入解析KV缓存 (qq.com)\nHow a Transformer works at inference vs training time - YouTube\n"},{"title":"方法记录","url":"/2023/12/26/%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86/%E6%96%B9%E6%B3%95%E8%AE%B0%E5%BD%95/","content":"查找新模型PyTorch库 timm有很多SOTA模型 huggingface/pytorch-image-models ，再结合 模型榜单 就能知道最新的模型了。\ntimm 库引用模型并打印结构\nmodel = timm.create_model(&#x27;coatnet_0_224&#x27;)for name, param in model.named_parameters():    print(f&quot;Parameter name: &#123;name&#125;, &#123;param.size()&#125;&quot;)\n","tags":["方法记录"]},{"title":"思想","url":"/2024/05/10/%E7%94%9F%E6%B4%BB%E6%83%85%E6%84%9F/%E6%80%9D%E6%83%B3/","content":"\n  463f9e316d1170d91999ca3c1874fb1bafeffb428b0c40ef5707938beebbd788e3d73d94ab606f04a423d4ba7b287006a10611108d48cd559c85b667630ec80835655baf905de1543a3298a302e5127373fb8cce0efa7d4a7c70840fd279070b7a5301ade292f460638208de4df8d03f55f3d9f1f9439f71423e86a331104773f2606f7073a5c8454b973707b8ea8c1294204cb094d8cfbcb6240b3c22f2f2306ab7f95eac029a4300f0a020c4fbefc051f126451225131d6ccf314f8b932c075b53d357b4d305692538c621b56acc07d2bd394577f6d1c32be68a106ce60e3d2ddfcabe435ee521bcea51c54e5876933ed6f358b37fdaf3f1ecb0182075d582236cfc5d08c7648c557592e21a933cba1337bf1ac75cf13506e30a730b4bc4d132383881dd04cb1a4a476165c1dc9b82927de4a89819a6db89063de878dfb44ba26854ebfb75ddeadd1473c8c7e80a5b0c32d519c42762ac5fd7c0663cd82162a7b1d0b3a266da14d9a0578cb5639d13e2d104a1c3218bbc5848b3767b9722dc\n  \n    \n      \n      \n        请输入密码后查看\n      \n    \n  \n\n","tags":["private","生活"]},{"title":"硬件知识","url":"/2024/03/13/%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86/%E7%A1%AC%E4%BB%B6%E7%9F%A5%E8%AF%86/","content":"NIC 网卡\n随机访问存储器RAM（Random Access Memory） /DDR/ HBM（High Bandwidth Memory） 都是内存\nPCIe switch  就是一个接口拓展，把硬件连接起来\nPCIe总线资料\nPCIe（一） —— 基础概念与设备树 | Soul Orbit (r12f.com)\nRDMA跨机直接访问内存的技术，会减少开销\n资料\n【最新】Nvidia GPU互联技术全景图 - 知乎 (zhihu.com)\n","tags":["硬件"]},{"title":"自我剖析","url":"/2024/05/09/%E7%94%9F%E6%B4%BB%E6%83%85%E6%84%9F/%E8%87%AA%E6%88%91%E5%89%96%E6%9E%90/","content":"\n  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\n  \n    \n      \n      \n        请输入密码后查看\n      \n    \n  \n\n","tags":["private","生活"]},{"title":"芙莉莲","url":"/2024/05/09/%E7%94%9F%E6%B4%BB%E6%83%85%E6%84%9F/%E8%8A%99%E8%8E%89%E8%8E%B2/","content":"总体小时候看的魔戒/霍比特人给我印象很深，很喜欢这种一行人冒险的故事（人类勇士，法师，矮人，精灵），慢节奏，风景又很好（温暖色调的）。芙莉莲也是这种风格，记录一下感想。\n人是需要被肯定的活在社会中，总体也算善良正义。我们都希望自己的一生是有所贡献，值得肯定的呀。\n\n所以当他人愿意说出自己的事迹，不要吝啬赞美，要给出肯定啊。\n\n人的心灵是很脆弱的，需要一些支撑，要不然也不会出现那么多宗教。这里的女神大人，应该是希望有个客观的‘神“来评判自己的一生。\n心理暗示人们大都需要积极的心理暗示。但是就算没拔出勇者之剑，老子依旧要去干倒魔王的勇气真的好可贵！\n还是要专心做事吧，之前的种种并不代表什么，比如啥高考成绩、被谁谁谁肯定/否定等。做事的时候仅仅是在做这件事而已，不要给自己太多心理暗示，如一定能做成（做不成）。\n\n","tags":["生活"]},{"title":"Linux使用","url":"/2022/12/12/%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86/%E5%AE%8C%E7%BB%93/Linux%E4%BD%BF%E7%94%A8/","content":"linux的基本使用。\n本地用wsl就可以，在线colab网站也挺好。\n好用命令查找文件。/ : 从根目录开始查找。\nfind / -name &quot;local&quot;\n查找进程。grep是搜索，用kill杀死进程。\nps aux | grep bash\n后台运行。nohup , &amp;  , 2&gt;&amp;1 将错误输出重定向到标准输出\nnohup ./clash-linux-amd64-v1.10.0 -f xiaoyin_linux.yml -d . &gt; clash.log 2&gt;&amp;1 &amp;\n 修改权限。\nchmod 777 test.txt \nwhereis\n常用配置更换pip清华源，快的飞起。  有时候换科大源快，可能离得近吧。\npip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\nWSL2windows开启Linux子系统设置\n微软商店下个20.04ubuntu\n再在vscode中打开，linus编程比windows好很多。\n","tags":["linux"]},{"title":"Megatron-LM实验","url":"/2023/10/19/%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86/%E5%AE%8C%E7%BB%93/Megatron-LM%E5%AE%9E%E9%AA%8C/","content":"运行megatron代码注释trans engine模块，参数   —transformer-impl local \n创建环境\ndocker run -it --name ydshi_3_1 --gpus all --shm-size=1G -v /home/ydshi/data:/workspace nvcr.io/nvidia/pytorch:22.04-py3 /bin/bash\ngpt需要下载vocab，merges 2个文件，可以在hugging face下载到。按官网教程预处理数据。将sh脚本补充完整，并自定义好参数，GPUS_PER_NODE、tp、pp等。\n运行命令就可以了。\nbash examples/pretrain_gpt_distributed_with_mp.sh &gt; record.txt \ntipsno.1CUDA out of memory，就是显存不够了，可以减小一些参数。\n​    —num-layers 12 \\​    —hidden-size 256  \n统计nccl通信占比在interation 代码前后插入 torch.cuda.nvtx.range_push   、 …pop tag。运行时前面加上nsys profile，在windows 使用NsightSystems 进行可视化查看。（一般第一个iteration是warm up，可以设置成5、10）\n\n下载并安装师兄改版的pyprof。在megatron-LM/result中\n使用 myrun.sh 将nsys文件转化成 csv表格。在可视化文件中复制iteration的信息（要找default stream），如图。\nName\tStart\tDuration\tTID\tGPU\tContextDescription of the event [968.163 ms]\t18.0755s\t968.163 ms\t117199\tGPU 1\tStream 7\n复制到interation.py, 再改下文件名，运行interation.py这个就行，\n会调用到algo.py ，统计kernel时间的。\nmyrun.shnsys profile bash examples/pretrain_gpt_distributed_with_mp.sh &gt; record.txt nsys stats --report=sqlite  pp4.nsys-reppython3 -m pyprof.parse pp4.sqlite &gt; pp4.jsonpython3 -m pyprof.prof --csv -c idx,kernel,sil,device,stream,start,end,grid,block pp4.json &gt; pp4.csv\n","tags":["Megatron-LM"]},{"title":"Docker使用","url":"/2024/04/09/%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86/%E5%AE%8C%E7%BB%93/docker%E4%BD%BF%E7%94%A8/","content":"dockerpython ，pytorch，cuda都要相互兼容。可以用官方提供的docker，如nvidia。\ncuda版本查看 ，其他的如nvidia-smi都不是。\npython -c &quot;import torch; print(torch.version.cuda)&quot;\ndocker run的时候要-v挂载数据， —shm-size扩大空间。docker工作目录命名为workspace，还得重新命名。\ndocker run -it --name ydshi_3_1 --gpus all --shm-size=1G -v /home/ydshi/data:/workspace nvcr.io/nvidia/pytorch:22.04-py3 /bin/bash\n创建完容器之后重新打开\ndocker start ydshi_3_1docker exec -it ydshi_3_1 /bin/bash \n查看镜像        docker images\n查看容器        docker ps \nssh连接需要用户名、ip地址、密码。默认端口22。\nssh username@host\n可以在vscode里面下载ssh插件，打开服务器的文件夹\n心得docker也需要用  conda  来管理环境的，不过默认在用base。\nvscode可直接连接到docker，再选择docker里面的conda python解释器，就可以跳转、查看参数了。\npylance类型检查报错，可以在vscode setting里面关闭。\n\n最后能在服务器里面愉快的编程了。\n","tags":["docker"]},{"title":"博客使用","url":"/2022/09/02/%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86/%E5%AE%8C%E7%BB%93/hexo%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8/","content":"hexo+keep主题的静态网站。\n我需要的博客功能：    \nA：代码折叠，数学公式，简洁美观。\n文章不太想公开：\nA：用密码访问，在github仓库能看到。Hexo加密   \n还能放在_draft文件夹不上传，在本地先看着，这个别人完全看不到。\nGit Bash进入博客目录中（D:\\blog，D:\\blog\\source\\_posts都行）。\n常用命令：\nhexo clean  # 清除缓存hexo g      # 生成静态网页hexo s      #启动服务器，本地查看hexo d      # 部署到Github\n图床使用PicGO在github上创建图床，picgo要打开时间戳重命名。\n还要下载compress插件，搭配压缩网站（tinify.com)  。\ntypora平时就复制图片到统一文件夹如typora/img,是博客的文档就手动将图片上传。本地要发给别人也简单，用python脚本将图片移到同一文件夹，改下引用格式就行。\n数学公式如何在 hexo 中支持 Mathjax  这个实测简单好使\ntips1修改仓库,这样hexo d好使点\nrepository: git@github.com:shiyandong/shiyandong.github.io.git#repository: https://github.com/shiyandong/shiyandong.github.io.git\ntips2默认的git bash的框太丑了，也不能缩放。得把git bash加到windows终端里面。\n","tags":["blog"]},{"title":"深度学习基础","url":"/2023/12/01/%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86/%E5%AE%8C%E7%BB%93/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/","content":"常用方法Cross Entropy Loss交叉熵主要用于度量两个概率分布间的差异性。标签值 y（分类时用one-hot编码，真实类别是1，其他为0）， 预测值 a，分类数n\n\n\\text { loss }=-\\sum_{j=1}^n y_j \\ln a_jsoftmax多类别分类的激活函数，将一组实数转化为表示概率分布的值。每个元素都在 0 到 1 之间，且所有元素的和为 1。\n给定输入向量 $z=\\left(z_1, z_2, \\ldots, z_k\\right)$ ，计算公式为:\n\n\\begin{aligned}\n\\sigma(z)_i=\\frac{e^{z_i}}{\\sum_{j=1}^k e^{z_j}}，i=1,2, \\ldots, k\n\\end{aligned}其中， $e$ 是自然对数的底， $k$ 是类别的数量。\nlarynorm\n用于加速训练的。对单个样本的不同特征做归一化操作，公式：\n\n\\begin{aligned}\n\\mu_i & =\\frac{1}{n} \\sum_{j=1}^n x_{i j} \\\\\n\\sigma_i^2 & =\\frac{1}{m} \\sum_{j=1}^m\\left(x_{i j}-\\mu_i\\right)^2 \\\\\n\\hat{x}_{i j} & =\\frac{x_{i j}-\\mu_i}{\\sqrt{\\sigma_i^2+\\epsilon}}\n\\end{aligned}\n\\begin{aligned}\n\n\n \\end{aligned}dropout用于防止神经网络过拟合。在训练过程中，随机地将一部分神经元的输出设置为零。\n资料\n03.2 交叉熵损失函数 - AI-EDU (microsoft.github.io)\n优化器深度学习的优化目标是最小化目标（损失）函数，就是反向传播算梯度从而更新参数。不同优化器区别在于q函数。\n待优化参数: $\\theta$ ，目标函数： $f(\\theta)$ ，学习率: $\\alpha$\n $\\mathrm{t}$ 时刻参数的梯度: $g_t=\\nabla f\\left(\\theta_t\\right)$\n优化通式：  $\\theta_t=\\theta_{t-1}-q\\left(g_t\\right)$\nSGDSGD的梯度下降过程，类似于一个小球从山坡上滚下，它的前进方向只与当前山坡的最大倾斜方向一致(梯度反方向)，每一个时刻的初速度都为０。\n\n\\begin{aligned}\n\n\\theta_t=\\theta_{t-1}-\\alpha * g_t\n\n \\end{aligned}SGD容易收敛到局部最优，在某些情况下可能被困在鞍点。\n引入 Momentum \n\n\\begin{aligned}\n\nm_t & =\\text { momentum } * m_{t-1}+\\alpha * g_t \\\\\n\\theta_t & =\\theta_{t-1}-m_t\n\n\\end{aligned}假设momentum =0.9,$ \\alpha=0.01$, 有:\n\n\\begin{aligned}\n& m_5=0.9 m_4+0.01 g_5 \\\\\n& m_4=0.9 m_3+0.01 g_4 \\\\\n& m_3=0.9 m_2+0.01 g_3 \\\\\n& m_2=0.9 m_1+0.01 g_2\n\\end{aligned}则: $m_5=0.01 *\\left(g_5+0.9 g_5+0.9^2 g_3+0.9^3 g_2+0.9^4 g_1\\right)$可以看到第5次更新的梯度包含了前4次的梯度，且是一个指数衰减的过程。\nSGD Momentum的梯度下降过程，前进方向由当前山坡的最大倾斜方向与之前的下降方向共同决定，小球具有初速度(动量)。\nAdam\n\\begin{aligned}\nm_t & =\\beta_1 m_{t-1}+\\left(1-\\beta_1\\right) g_t \\\\\n\\hat{m}_t & =\\frac{m_t}{1-\\beta_1^t} \\\\\nV_t & =\\beta_2 V_{t-1}+\\left(1-\\beta_2\\right) g_t^2 \\\\\n\\hat{V}_t & =\\frac{V_t}{1-\\beta_2^t} \\\\\n\\alpha_t & =\\frac{\\alpha}{\\sqrt{\\hat{V}_t}+\\epsilon} \\\\\n\\theta_t & =\\theta_{t-1}-\\alpha_t * \\hat{m}_t    \\\\\n\n\\end{aligned}二阶动量$V_t $ 是历史梯度平方和，度量历史更新频率。参数更新越频繁，二阶动量越大，学习率就越小。$\\hat{m}_t 、\\hat{V}_t$是偏差修正。\n资料\noptimizer优化器总结 - weber’s Blog (haiping.vip)\n反向传播就是求损失函数C对参数的梯度，利用梯度更新参数。\n反向计算梯度时，根据前向不同的计算公式，从而有相应的系数。\n资料 \nBack Propagation and Gradient Calculation in Deep Learning (hannlp.github.io)\n下篇 反向传播的微积分原理_哔哩哔哩_bilibili\n卷积神经网络(CNN)反向传播算法 - 刘建平Pinard - 博客园 (cnblogs.com)\nconv2d结构Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) \n这个卷积层参数：$64\\times3\\times9+64 = 1792$  \n一个通道的结果： 输入的3个通道各自经过一个卷积核再相加得到的，卷积核个数=输出通道*输入通道，每个通道还有有一个偏置。 \n资料\n卷积操作参数量和计算量       卷积核图示\n","tags":["深度学习"]}]